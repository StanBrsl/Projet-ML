{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880a9f97",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16521da6",
   "metadata": {},
   "source": [
    "Dans ce chapitre nous transformerons les données de telles sorte à ce qu'elles soient utilisables par des algorithmes de Machine Learning. C'est aussi pendant cette phase que nous trierons les données pour la suite du processus. Au cours de cette phase toute décision prise doit pouvoir être justifiée et expliquée de sorte à ce que le traitement des données et les résultats donnés par le modèle soient les plus précis possibles. \n",
    "\n",
    "Je commence par importer les datasets de travail qui illustrerons tous les exemples de ce document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242108cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path : C:/Users/Stanislas Brusselle/OneDrive/Documents/Projet ML sklearn/des-fichiers-complementaires-3-049-ko/Telechargement/data/iris.csv\n",
      "path : C:/Users/Stanislas Brusselle/OneDrive/Documents/Projet ML sklearn/des-fichiers-complementaires-3-049-ko/Telechargement/data/titanic_train.csv\n",
      "path : C:/Users/Stanislas Brusselle/OneDrive/Documents/Projet ML sklearn/des-fichiers-complementaires-3-049-ko/Telechargement/data/boston.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog as fd\n",
    "\n",
    "def select_file_csv():\n",
    "    \n",
    "    init = \"C:\\\\Users\\\\Stanislas Brusselle\\\\OneDrive\\\\Documents\\\\Projet ML sklearn\\\\des-fichiers-complementaires-3-049-ko\\\\Telechargement\\\\data\"\n",
    "    \n",
    "    file_type = (('csv file', '*.csv'), ('All file', '*.*'))\n",
    "    file_name = fd.askopenfilename(initialdir = init, title='Fichiers', filetypes = file_type)\n",
    "    \n",
    "    return file_name\n",
    "\n",
    "def select_file_txt():\n",
    "    \n",
    "    init = \"C:\\\\Users\\\\Stanislas Brusselle\\\\OneDrive\\\\Documents\\\\Projet ML sklearn\\\\des-fichiers-complementaires-3-049-ko\\\\Telechargement\\\\data\"\n",
    "    \n",
    "    file_type = (('csv file', '*.txt'), ('All file', '*.*'))\n",
    "    file_name = fd.askopenfilename(initialdir = init, title='Fichiers', filetypes = file_type)\n",
    "    \n",
    "    return file_name\n",
    "\n",
    "def cvs_to_dataFrame():\n",
    "    \n",
    "    root=tk.Tk()  \n",
    "    root.overrideredirect(1)\n",
    "\n",
    "    path=select_file_csv()\n",
    "\n",
    "    root.destroy()\n",
    "    \n",
    "    print(\"path : \" + path)\n",
    "    \n",
    "    with open(path, mode='r') as file : \n",
    "        fichier = pd.read_csv(file)\n",
    "        \n",
    "    return fichier\n",
    "\n",
    "def txt_to_dataFrame(nom_colonnes, skip_rows):\n",
    "    \n",
    "    root=tk.Tk()  \n",
    "    root.overrideredirect(1)\n",
    "\n",
    "    path=select_file_txt()\n",
    "\n",
    "    root.destroy()\n",
    "    \n",
    "    print(\"path : \" + path)\n",
    "    \n",
    "    with open(path, mode='r') as file : \n",
    "        fichier = pd.read_fwf(file, skip_rows=skip_rows, header=None, names=nom_colonnes)\n",
    "\n",
    "    return fichier\n",
    "\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "iris_df = cvs_to_dataFrame()\n",
    "titanic_df = cvs_to_dataFrame()\n",
    "boston_df = txt_to_dataFrame(names, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85628b23",
   "metadata": {},
   "source": [
    "# 1) Limitation des données et enregistrements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78302c4",
   "metadata": {},
   "source": [
    "## 1.1) Supprimer des colonnes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394eb3b",
   "metadata": {},
   "source": [
    "Il y a deux manières : \n",
    "- indiquer les colonnes à garder\n",
    "- supprimer les colonnes \n",
    "\n",
    "Pour supprimer une colonne : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39077bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_width     float64\n",
       "petal_length    float64\n",
       "petal_width     float64\n",
       "class            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def del_column(dataset, column):\n",
    "    new_df=dataset.drop(columns=[column])\n",
    "    return new_df\n",
    "\n",
    "del_column(iris_df, 'sepal_length').dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46d392",
   "metadata": {},
   "source": [
    "Pour indiquer les colonnes à garder, il fauit créer un nouveau dataFrame comme ci-dessous : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4133335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal_length    float64\n",
       "class            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modif_del_column(dataset, columns):\n",
    "    new_df=dataset[columns]\n",
    "    return new_df\n",
    "\n",
    "modif_del_column(iris_df, ['petal_length', 'class']).dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42a538",
   "metadata": {},
   "source": [
    "## 1.2) Supprimer des enregistrements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e751c9c6",
   "metadata": {},
   "source": [
    "Il est possible de supprimer un enregistrement en indiquant la ligne mais cette méthode n'est pas otpimale. En effet, en faisant cela vous risquez de modifier complètement le dataset en supprimant une données nécessaire. Il est préférable d'utiliser la fonction dropna. Celle-ci demande en paramètre : \n",
    "- l'axe (axis) 0 pour les lignes et 1 pour les colonnes\n",
    "- une méthode (how) qui vaut any ou all \n",
    "- subset pour préciser un sous-ensemble des colonnes à utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "160b7a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    714\n",
       "Survived       714\n",
       "Pclass         714\n",
       "Name           714\n",
       "Sex            714\n",
       "Age            714\n",
       "SibSp          714\n",
       "Parch          714\n",
       "Ticket         714\n",
       "Fare           714\n",
       "Cabin          185\n",
       "Embarked       714\n",
       "zscore_Fare    714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Supprime toutes les lignes où l'age est vide \n",
    "def del_empty_case(dataset, subset):\n",
    "    new_df = titanic_df.dropna(axis=0, subset=[subset]).reset_index(drop=True)\n",
    "    return new_df\n",
    "\n",
    "del_empty_case(titanic_df, 'Age').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b440ab",
   "metadata": {},
   "source": [
    "On peut également filtrer les lignes selon une condition au moyen de la commande suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ea3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=titanic_df[titanic_df['Sex']=='femelle']\n",
    "new_df=titanic_df[(titanic_df['Sex']=='femelle')&(titanic_df['Age']>=21)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4215cf2",
   "metadata": {},
   "source": [
    "# 2) Séparer le dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f964c",
   "metadata": {},
   "source": [
    "Dans cette partie nous séparerons le dataset de sorte à obtenir un dataset d'entrainement et un dataset de test. \n",
    "\n",
    "Data snooping : analyser les données trop finement sans avoir extrait le dataset d'entrainement\n",
    "\n",
    "Au cours du processus de modélisation, le dataset d'entrainement sera à nouveau séparé entre apprentissage et validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41338f",
   "metadata": {},
   "source": [
    "## 2.1) Séparation aléatoire "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9061a0e",
   "metadata": {},
   "source": [
    "Il faut d'abord mélanger le dataset avant d'effectuer toute opération. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d461987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sélectionne un échantillon mélangé de 80% de l'ensemble des données de titanic_df\n",
    "train_titanic = titanic_df.sample(frac=0.8, random_state=42)#42 la réponse universelle\n",
    "test_titanic = titanic_df.drop(train_titanic.index)\n",
    "#optionnel : mélanger le dataset d'entrainement\n",
    "test_titanic = test_titanic.sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7630ff2",
   "metadata": {},
   "source": [
    "## 2.2) Séparation stratifiée "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dad62b",
   "metadata": {},
   "source": [
    "Le dataset est séparé en amont selon la valeur d'une variable, puis chacune de ces catégories sera séparée selon le taux souhaité. Il faut d'abord vérifier qu'il existe une colonne catégorielle possédant peu de valeurs différentes car la séparation stratifiée focntionne mal sur des catégories trop éclatée. Il faut finalement grouper les données par catégories et faire un sample dans chacune d'elles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6ec50c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille donnees d entrainement :  713\n",
      "taille donnees de teste :  178\n"
     ]
    }
   ],
   "source": [
    "def stratified_seperation(dataset, frac, column):\n",
    "    \n",
    "    train_dataset=dataset.groupby(column, group_keys=False).apply(lambda x : x.sample(frac=frac, random_state=42))\n",
    "    test_dataset = dataset.drop(train_dataset.index)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "seperation=stratified_seperation(titanic_df, 0.8, 'Sex')\n",
    "\n",
    "\n",
    "print('taille donnees d entrainement : ',seperation[0].shape[0])\n",
    "print('taille donnees de teste : ', seperation[1].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b9c6d8",
   "metadata": {},
   "source": [
    "# 3) Traiter les données manquantes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72008be6",
   "metadata": {},
   "source": [
    "Il existe trois méthodes (dont deux déjà vues précédemment) : \n",
    "- Supprimer la colonne incriminée\n",
    "- Supprimer les lignes où des valeurs sont manquantes\n",
    "- Remplir les valeurs manquantes par des valeurs décidée en amont, le padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80a1eb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       891\n",
       "zscore_Fare    891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def append_value_empty_cases(dataset, column, value) :\n",
    "    dataset[column] = dataset[column].fillna(value)\n",
    "    return dataset\n",
    "append_value_empty_cases(titanic_df, 'Fare', 'S').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62b27c",
   "metadata": {},
   "source": [
    "# 4) Préparer les attributs numériques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5a8b6",
   "metadata": {},
   "source": [
    "Pour préparer les données, il existe plusieurs possibilités cumulables : \n",
    "- la validation des données\n",
    "- le feature engineering \n",
    "- la dicrétisation \n",
    "- la normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26962e64",
   "metadata": {},
   "source": [
    "## 4.1) La validation des données "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c364e",
   "metadata": {},
   "source": [
    "Une fois deux plus cette méthode contient deux aspects : \n",
    "- Sémantique : vérifier que les valeurs fournies correspondent au sens de la colonne et à son contexte.\n",
    "- Statistique : trouver les données dont la valeur est peu probable par rapport aux autres valeurs. \n",
    "\n",
    "Pour la méthode statistique on regardera l'écart à la moyenne, la valeur absolue du z-score et l'écart au premier quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbad5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_statique_ecart_moyenne(dataset, column):\n",
    "    \n",
    "    std = dataset[column].std()#calcul de l'écart type\n",
    "    mean = dataset[column].mean()#calcul de la moyenne \n",
    "    limit_low = mean - 3 * std #calcul de la limite basse de filtrage : distance de trois fois l'écart type à la médiane. \n",
    "    limit_high = mean + 3 * std#de même pour la limite haute \n",
    "    \n",
    "    new_df=dataset[dataset[column].between(limit_low, limit_high)]#applique les changements au dataset\n",
    "    \n",
    "    return new_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1132da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max dataset non filtre :  512.3292\n",
      "nbr data :  891\n",
      "\n",
      "Max dataset filtre : 164.8667\n",
      "nbr data :  871\n",
      "\n",
      "donnees retirees :  20\n"
     ]
    }
   ],
   "source": [
    "print('Max dataset non filtre : ', max(titanic_df['Fare']))\n",
    "print('nbr data : ', titanic_df.shape[0])\n",
    "print()\n",
    "\n",
    "new_dataset = validation_statique_ecart_moyenne(titanic_df, 'Fare')\n",
    "\n",
    "print('Max dataset filtre :', max(new_dataset['Fare']))\n",
    "print('nbr data : ', new_dataset.shape[0])\n",
    "print()\n",
    "\n",
    "print('donnees retirees : ', titanic_df.shape[0]-new_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2981eb",
   "metadata": {},
   "source": [
    "z_score = (X - moyenne)/(écart_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4227fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consiste à calculer la distance entre la valeur et la moyenne en terme d'écarts types\n",
    "def validation_statique_z_score(dataset, column):\n",
    "    zscore = 'zscore_'+column\n",
    "    dataset[zscore]=(dataset[column]-dataset[column].mean())/(dataset[column].std())\n",
    "#La valeur absolue du du z-score pour ne garder que les données pourn lesquelles elle est inférieure à 3.     \n",
    "    new_df = dataset[dataset[zscore].abs()<3]\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10835625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max dataset non filtre :  512.3292\n",
      "nbr data :  891\n",
      "\n",
      "Max dataset filtre : 164.8667\n",
      "nbr data :  871\n",
      "\n",
      "donnees retirees :  20\n"
     ]
    }
   ],
   "source": [
    "print('Max dataset non filtre : ', max(titanic_df['Fare']))\n",
    "print('nbr data : ', titanic_df.shape[0])\n",
    "print()\n",
    "\n",
    "new_dataset = validation_statique_z_score(titanic_df, 'Fare')\n",
    "\n",
    "print('Max dataset filtre :', max(new_dataset['Fare']))\n",
    "print('nbr data : ', new_dataset.shape[0])\n",
    "print()\n",
    "\n",
    "print('donnees retirees : ', titanic_df.shape[0]-new_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa82e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_statique_ecart_type(dataset, column):\n",
    "    \n",
    "    q1 = dataset[column].quantile(0.25)#Premier quartile\n",
    "    q3 = dataset[column].quantile(0.75)\n",
    "    \n",
    "    diff=q3-q1\n",
    "    \n",
    "#Création d'une limite basse et d'une limite haute \n",
    "\n",
    "    limit_low = q1 - 1.5*diff\n",
    "    limit_high = q3 + 1.5*diff\n",
    "    \n",
    "    new_df=dataset[dataset[column].between(limit_low, limit_high)]\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef2db1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max dataset non filtre :  512.3292\n",
      "nbr data :  891\n",
      "\n",
      "Max dataset filtre : 65.0\n",
      "nbr data :  775\n",
      "\n",
      "donnees retirees :  116\n"
     ]
    }
   ],
   "source": [
    "print('Max dataset non filtre : ', max(titanic_df['Fare']))\n",
    "print('nbr data : ', titanic_df.shape[0])\n",
    "print()\n",
    "\n",
    "new_dataset = validation_statique_ecart_type(titanic_df, 'Fare')\n",
    "\n",
    "print('Max dataset filtre :', max(new_dataset['Fare']))\n",
    "print('nbr data : ', new_dataset.shape[0])\n",
    "print()\n",
    "\n",
    "print('donnees retirees : ', titanic_df.shape[0]-new_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142fa33",
   "metadata": {},
   "source": [
    "## 4.2) Feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455b26f",
   "metadata": {},
   "source": [
    "Correspond au fait de créer de nouvelles colonnes à partir des données de colonnes déjà existantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d194f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['petal_area']=iris_df['petal_length']*iris_df['petal_width']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856883f3",
   "metadata": {},
   "source": [
    "## 4.3) Discrétisation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8235bf5",
   "metadata": {},
   "source": [
    "Action de transformer une variable numérique en une variable catégorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "398205f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_df['Age'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d213ee",
   "metadata": {},
   "source": [
    "Cette distribution n'est ni uniforme ni normale. Il pourrait être intéressant de faire des catégories d'ages plutôt que d'afficher l'age directement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c2d722",
   "metadata": {},
   "source": [
    "### 4.3.1) Intervalles égaux "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9171666b",
   "metadata": {},
   "source": [
    "bins : nombre d'intervalle\n",
    "\n",
    "=> adapté pour les distributions plutôt uniformes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e08ee9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.336, 32.252]    346\n",
       "(32.252, 48.168]    188\n",
       "(0.34, 16.336]      100\n",
       "(48.168, 64.084]     69\n",
       "(64.084, 80.0]       11\n",
       "Name: Age_bins, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Age_bins']=pd.cut(titanic_df['Age'], bins=5)\n",
    "titanic_df['Age_bins'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737156ff",
   "metadata": {},
   "source": [
    "### 4.3.2) Répartition par quartile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3f05963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.419, 19.0]    164\n",
       "(31.8, 41.0]     144\n",
       "(41.0, 80.0]     142\n",
       "(19.0, 25.0]     137\n",
       "(25.0, 31.8]     127\n",
       "Name: Age_quantiles, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Age_quantiles']=pd.qcut(titanic_df['Age'], q=5)\n",
    "titanic_df['Age_quantiles'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba2296",
   "metadata": {},
   "source": [
    "### 4.3.3) Répartition manuelle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca0c4826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mature    241\n",
       "Young     205\n",
       "Teen      133\n",
       "Child      71\n",
       "Senior     64\n",
       "Name: Age_manual, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Age_manual']=pd.cut(titanic_df['Age'], bins=[0,13,21,30,50,90], \n",
    "                                labels = ['Child', 'Teen', 'Young', 'Mature', 'Senior'])\n",
    "titanic_df['Age_manual'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61120bf8",
   "metadata": {},
   "source": [
    "## 4.4) Normaliser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b5cf8",
   "metadata": {},
   "source": [
    "A pour but de ramener toutes les valeurs à une échelle où elles peuvent être comparées. Dans cette partie je créerai des fonctions de normalisation dites robuste et standard. La fonction de normalisation robuste consiste à centrer les données sur la médiane (q2) et à uniformiser l'écart interquartile (q3-q1) qui deviendra l'unité. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e89b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robuste_scaling(dataset, column):\n",
    "    \n",
    "    q1 = dataset[column].quantile(0.25)\n",
    "    q3 = dataset[column].quantile(0.75)\n",
    "    \n",
    "    diff = q3 - q2\n",
    "\n",
    "    q2 = dataset[column].mean()\n",
    "    \n",
    "    dataset[column]=(dataset[column]-q2)/(diff)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def standard_scaling(dataset, column):\n",
    "    \n",
    "    mean = dataset[column].mean()\n",
    "    std = dataset[column].std()\n",
    "    dataset[column]=(dataset[column]-mean)/std\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274e0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
